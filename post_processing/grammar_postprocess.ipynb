{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from PYEVALB import scorer\n",
    "from PYEVALB import parser, tree\n",
    "from nltk.tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seqs_file = '/home/ta/Projects/RNNG_all/rnng_self/data/post_processing/pred_seqs.txt'\n",
    "test_seqs_file = '/home/ta/Projects/RNNG_all/rnng_self/data/post_processing/test_seqs.txt'\n",
    "train_seqs_file = '/home/ta/Projects/RNNG_all/rnng_self/data/post_processing/train_seqs.txt'\n",
    "dev_seqs_file = '/home/ta/Projects/RNNG_all/rnng_self/data/post_processing/dev_seqs.txt'\n",
    "test_seqs = open(test_seqs_file, 'r').readlines()\n",
    "pred_seqs = open(pred_seqs_file, 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def no_X_grammar(grammar):\n",
    "    no_X_grammar = []\n",
    "    for rule in grammar:\n",
    "        # print (rule)\n",
    "        if str(rule.lhs()) == 'XX':\n",
    "            # print ('XX -> sth = ', rule)\n",
    "            continue\n",
    "        rule = str(rule).replace('XX', '')\n",
    "        rule = re.sub(' +', ' ', rule)\n",
    "        rule = rule.strip()\n",
    "        no_X_grammar.append(rule)\n",
    "    return set(no_X_grammar)\n",
    "\n",
    "\n",
    "def get_grammar(seq_file, no_XX):\n",
    "    def no_X_rule(rule):\n",
    "        if str(rule.lhs()) == 'XX':\n",
    "            # print ('XX -> sth = ', rule)\n",
    "            return None\n",
    "        # rule = str(rule).replace('XX', '')\n",
    "        rule = re.sub('XX', '', str(rule))\n",
    "        rule = re.sub(' +', ' ', rule)\n",
    "        rule = rule.strip()\n",
    "        return rule\n",
    "\n",
    "    grammar = set()\n",
    "    f = open(seq_file, 'r')\n",
    "    seqs = f.readlines()\n",
    "    print ('Get grammar: len of', seq_file, '=', len(seqs))\n",
    "#     print ('Getting grammar...')\n",
    "    rule_counter = Counter()\n",
    "    for line in seqs:\n",
    "        tree = Tree.fromstring(line)\n",
    "        rules = tree.productions()\n",
    "        grammar.update(rules)\n",
    "        if no_XX:\n",
    "            no_X_rules = [no_X_rule(rule) for rule in tree.productions()]\n",
    "            no_X_rules = [rule for rule in no_X_rules if rule is not None]\n",
    "            rules = no_X_rules\n",
    "        rule_counter.update(rules)\n",
    "\n",
    "    if no_XX:\n",
    "        assert len(no_X_grammar(grammar)) == len(rule_counter)\n",
    "        return no_X_grammar(grammar), rule_counter\n",
    "    else:\n",
    "        return grammar, rule_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get grammar: len of /home/ta/Projects/RNNG_all/rnng_self/data/post_processing/train_seqs.txt = 39831\n",
      "Get grammar: len of /home/ta/Projects/RNNG_all/rnng_self/data/post_processing/dev_seqs.txt = 1700\n"
     ]
    }
   ],
   "source": [
    "train_grammar, _ = get_grammar(train_seqs_file, no_XX=False) \n",
    "dev_grammar, _ = get_grammar(dev_seqs_file, no_XX=False)\n",
    "train_grammar.update(dev_grammar) \n",
    "# print (train_grammar[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VP -> XX PRT S S XX S, XX -> 'refers', XX -> 'noble', XX -> 'downgrade', XX -> 'anxiously']\n",
      "29284\n",
      "VP -> XX PRT S S XX S\n"
     ]
    }
   ],
   "source": [
    "print (list(train_grammar)[:5])\n",
    "print (len(train_grammar))  \n",
    "example = (list(train_grammar)[0]) \n",
    "print (str(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting grammar from /home/ta/Projects/RNNG_all/rnng_self/data/post_processing/train_seqs.txt\n",
      "Done at 39831 lines.\n",
      "There are 29162 productions\n",
      "Grammar: [('NP -> XX XX', 90469), ('PP -> XX NP', 85682), ('NP -> XX', 65595), ('XX -> ,', 48723), ('XX -> the', 41107), ('NP -> XX XX XX', 40655), ('XX -> .', 39019), ('TOP -> S', 36165), ('VP -> XX VP', 35836), ('NP -> NP PP', 34965)]\n",
      "\n",
      "Getting grammar from /home/ta/Projects/RNNG_all/rnng_self/data/post_processing/dev_seqs.txt\n",
      "Done at 1700 lines.\n",
      "There are 6554 productions\n",
      "Grammar: [('NP -> XX XX', 3777), ('PP -> XX NP', 3519), ('NP -> XX', 2543), ('XX -> ,', 2143), ('XX -> the', 1873), ('NP -> XX XX XX', 1729), ('XX -> .', 1660), ('TOP -> S', 1521), ('NP -> NP PP', 1452), ('VP -> XX VP', 1345)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_grammar_from_file_new(seq_file):\n",
    "    def no_quote_prod(prod):\n",
    "        prod = re.sub('\\'', '', str(prod))\n",
    "        prod = re.sub(' +', ' ', prod)\n",
    "        return prod.strip()\n",
    "\n",
    "    print ('Getting grammar from', seq_file)\n",
    "    f = open(seq_file, 'r')\n",
    "    # grammar = None \n",
    "    prod_counter = Counter() \n",
    "    prods = []\n",
    "    cnt_line = 0\n",
    "    for seq in f:\n",
    "        cnt_line += 1\n",
    "        tree = parser.create_from_bracket_string(seq)\n",
    "        this_seq_prods, _ = tree.productions(skip_XX=False, skip_span=True)\n",
    "        this_seq_prods = [no_quote_prod(prod) for prod in this_seq_prods]\n",
    "        prods.extend(this_seq_prods) \n",
    "        prod_counter.update(this_seq_prods)\n",
    "\n",
    "    print ('Done at', cnt_line, 'lines.')\n",
    "    print ('There are', len(set(prods)), 'productions')\n",
    "    print ('Grammar:', prod_counter.most_common(10))\n",
    "    print ('')\n",
    "    return set(prods), prod_counter\n",
    "\n",
    "train_grammar_self, _ = get_grammar_from_file_new(train_seqs_file)\n",
    "train_grammar_self.update(get_grammar_from_file_new(dev_seqs_file)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XX -> inch', 'TOP -> SBARQ', 'XX -> fleet', 'XX -> USG', 'XX -> own']\n",
      "29283\n"
     ]
    }
   ],
   "source": [
    "train_grammar_self = list(train_grammar_self)\n",
    "print (list(train_grammar_self)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29283 29284\n",
      "VP -> XX PRT S S XX S\n",
      "XX -> inch\n",
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "train_grammar_str = [str(e) for e in train_grammar] \n",
    "print (len(train_grammar_self), len(train_grammar_str))\n",
    "print (train_grammar_str[0]) \n",
    "print (train_grammar_self[0])\n",
    "outside = [e for e in train_grammar_self if e not in train_grammar_str] \n",
    "outside = [e for e in outside if 'XX ->' not in e]\n",
    "print (len(outside))\n",
    "print (outside) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
